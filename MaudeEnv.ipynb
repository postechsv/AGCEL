{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f67135",
   "metadata": {},
   "source": [
    "# 2/5/2024 랩미팅\n",
    "## goal\n",
    "* 워크샵 버전 (DP 모델링을 파이썬에서 함) -> 업데이트: DP 모델은 maude로 하고, python maude binding을 이용하여 강화학습\n",
    "* progress: 재현 성공\n",
    "\n",
    "## key idea\n",
    "#### Propositional Interface\n",
    "- 현재까지 관찰 결과, DP(5)의 학습결과를 DP(6)에 \"이어붙일\" 수 있었음. (성능과 별개로. 이 경우는 성능\"까지\" 성공적으로 전달했음)\n",
    "- 왜냐면 두 모델이 AP = { E.Think, E.Hungry, E.Single, E.Eat } 를 \"공유\"하기 때문\n",
    "- 즉, 위의 AP는 \"인터페이스\"로서 개념적으로 M = { DP(5), DP(6), ... } 라는 \"(possibly infinite) class of models\"를 denote하는 역할\n",
    "\n",
    "- 과연 parameterized model이 아닌 전혀 다른 모델끼리도 이 접근이 유효할까? e.g. Paxos -> Raft\n",
    "- 예를 들어, M = { consensus protocols }를 포착하는 AP를 찾을 수 있어서 그것을 인터페이스로 하는 휴리스틱 러닝이 가능할까?\n",
    "\n",
    "=> 인터페이스를 공유하는 maude model 2개만 얻으면 아래 코드를 거의 그대로 이용해서 실험해볼 수 있을듯\n",
    "\n",
    "#### Abstraction & Refinement\n",
    "- configuration은 AP를 feature로 하는 feature vector로 인코딩됨.\n",
    "- 당연히 명제 p가 추가되면 refinement고 삭제되면 abstraction임.\n",
    "- 예를 들어 {p,q,r}을 사용한다면 특정 상태는 3차원 불리언벡터이므로 8 x 8 테이블이 학습됨\n",
    "- 학습된 테이블을 잘 관찰해보면 q들 사이에 모종의 패턴이 있을 수가 있음 (아래 코드의 출력 참고)\n",
    "\n",
    "- 직관적으로, 아귀만 맞으면 비슷한 q값을 가지는 셀을(즉, index를) merge할 수 있지 않을까? e.g. 000 ~ 001 로 merge\n",
    "- 000, 001, ..., 111 총 8개의 엔트리가 있을때 \"가장 좋은\" pairwise matching을 찾는 문제\n",
    "- index의 best matching을 찾으면 그 결과를 예를 들어 {p, q, r} -> {p or q, q and r} 등으로 symbolic 하게 대응 시킬 수 있음.\n",
    "- 토너먼트 형식으로 1라운드씩 할때마다 명제의 개수는 하나씩 줄어들음 (abstraction step)\n",
    "- 그렇게 해서 얻어진 p or q, q and r은 일종의 \"학습된 패턴\"의 역할을 하지 않을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5217ea",
   "metadata": {},
   "source": [
    "```\n",
    "fmod DINING-PHILOSOPHERS-FUNCS is\n",
    "  protecting NAT .\n",
    "  sorts Status .    \n",
    "  ops think hungry single eat : -> Status [ctor] .\n",
    "\n",
    "  op #N : ~> Nat .  --- total number of philosophers\n",
    "  vars I J : Nat .  \n",
    "  \n",
    "  ops lc rc : Nat ~> Nat .    \n",
    "  eq lc(I) = I .    \n",
    "  ceq rc(I) = s(I) if (s(I) < #N) = true .\n",
    "  ceq rc(I) = 0 if (s(I) == #N) = true .\n",
    "\n",
    "  op adj : Nat Nat ~> Bool .\n",
    "  eq adj(I,J) = (J == lc(I)) or (J == rc(I)) .\n",
    "endfm\n",
    "\n",
    "mod DINING-PHILOSOPHERS is\n",
    "  including DINING-PHILOSOPHERS-FUNCS .\n",
    "\n",
    "  sorts Phil Chop Conf .\n",
    "  subsorts Phil Chop < Conf .   \n",
    "\n",
    "  op p : Nat Status -> Phil [ctor] .\n",
    "  op c : Nat -> Chop [ctor] .    \n",
    "  \n",
    "  op none : -> Conf [ctor] .\n",
    "  op _||_ : Conf Conf -> Conf [ctor comm assoc id: none] .\n",
    "\n",
    "  --- eq #N = s(s(s(0))) . \n",
    "  \n",
    "  vars I J : Nat .\tvar C : Conf .\t\n",
    "  \n",
    "  *** defining the system behavior with localized fairness\n",
    "  *** NOTE: rule attributes also declare the simplified version of\n",
    "  *** spatial action patterns, e.g., wake(I) = {'wake : 'I \\ I}\n",
    "\n",
    "  rl [th]: p(I,think) => p(I,hungry) .\n",
    "\n",
    " crl [hs]: p(I,hungry) || c(J) => p(I,single) \n",
    "   if adj(I,J) = true .\n",
    "\n",
    " crl [se]: p(I,single) || c(J) => p(I,eat) \n",
    "   if adj(I,J) = true .\n",
    "\n",
    "  rl [et]: p(I,eat) => p(I,think) || c(lc(I)) || c(rc(I)) .\n",
    "endm\n",
    "\n",
    "mod ABSTRACT-DINING-PHILOSOPHERS is\n",
    "  including DINING-PHILOSOPHERS .\n",
    "\n",
    "  sort AIdx .\n",
    "\n",
    "  ops hasThink hasHungry hasSingle hasEat : Conf -> Bool .\n",
    "  op aidx : Conf -> Nat .\n",
    "\n",
    "  var I : Nat . var C : Conf . var S : Status .\n",
    "\n",
    "  eq hasThink(p(I,think) || C) = true .\n",
    "  eq hasThink(p(I,S) || C) = hasThink(C) [owise] .\n",
    "  eq hasThink(c(I) || C) = hasThink(C) .\n",
    "  eq hasThink(none) = false .\n",
    "\n",
    "  eq hasHungry(p(I,hungry) || C) = true .\n",
    "  eq hasHungry(p(I,S) || C) = hasHungry(C) [owise] .\n",
    "  eq hasHungry(c(I) || C) = hasHungry(C) .\n",
    "  eq hasHungry(none) = false .\n",
    "\n",
    "  eq hasSingle(p(I,single) || C) = true .\n",
    "  eq hasSingle(p(I,S) || C) = hasSingle(C) [owise] .\n",
    "  eq hasSingle(c(I) || C) = hasSingle(C) .\n",
    "  eq hasSingle(none) = false .\n",
    "\n",
    "  eq hasEat(p(I,eat) || C) = true .\n",
    "  eq hasEat(p(I,S) || C) = hasEat(C) [owise] .\n",
    "  eq hasEat(c(I) || C) = hasEat(C) .\n",
    "  eq hasEat(none) = false .\n",
    " \n",
    "  eq aidx(C) = 8 * if hasThink(C) then 1 else 0 fi + 4 * if hasHungry(C) then 1 else 0 fi + 2 * if hasSingle(C) then 1 else 0 fi + 1 * if hasEat(C) then 1 else 0 fi .\n",
    "endm\n",
    "\n",
    "mod DP5 is\n",
    "  including ABSTRACT-DINING-PHILOSOPHERS .\n",
    "  \n",
    "  eq #N = 5 .\n",
    "endm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d94394fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import maude\n",
    "import random\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import tqdm\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "323986d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DP5 module\n"
     ]
    }
   ],
   "source": [
    "maude.init()\n",
    "maude.load('./dp.maude')\n",
    "m = maude.getCurrentModule()\n",
    "print('Using', m, 'module')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e082279d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p(0, single) || p(1, think) || c(1) || p(2, single) || c(2) || p(3, think) || p(4, hungry) || c(4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dp_generator():\n",
    "    N = random.choice([5])\n",
    "    P = [0] * N #np.zeros(N, dtype=int)\n",
    "    C = [1] * N #np.ones(N, dtype=int)\n",
    "\n",
    "    for i in range(N):\n",
    "        c = random.randrange(3)\n",
    "        if c == 1:\n",
    "            # to left\n",
    "            P[(i-1) % N] += 1\n",
    "            C[i] = 0\n",
    "        elif c == 2:\n",
    "            # to right:\n",
    "            P[i] += 1\n",
    "            C[i] = 0\n",
    "\n",
    "    # here, self.P[i] denotes the number of chopstics assigned for ith philos\n",
    "    for i in range(N):\n",
    "        if P[i] == 0:\n",
    "            P[i] = random.randrange(2) # either think or hungry\n",
    "        else:\n",
    "            P[i] += 1 # one chopstick or eat\n",
    "    \n",
    "    s = []\n",
    "    for i in range(N):\n",
    "        if P[i] == 0:\n",
    "            s.append(f'p({i},think)')\n",
    "        elif P[i] == 1:\n",
    "            s.append(f'p({i},hungry)')\n",
    "        elif P[i] == 2:\n",
    "            s.append(f'p({i},single)')\n",
    "        elif P[i] == 3:\n",
    "            s.append(f'p({i},eat)')\n",
    "            \n",
    "        if C[i] == 0:\n",
    "            pass\n",
    "        elif C[i] == 1:\n",
    "            s.append(f'c({i})')\n",
    "    return m.parseTerm(' || '.join(s))\n",
    "\n",
    "dp_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d229763",
   "metadata": {},
   "source": [
    "MaudeEnv does not know anything about the model in consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5113ed88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaudeEnv():\n",
    "    def __init__(self, g, init_term=None):\n",
    "        self.conf_gen = g\n",
    "        self.n_pred = 4\n",
    "        self.reset(init_term)\n",
    "        \n",
    "        #self.term = t\n",
    "        #self.aidx = self.get_aidx(t)\n",
    "        #self.nbrs = [(t,self.get_aidx(t)) for t,_,_,_ in t.search(1, m.parseTerm('X:Conf'), depth = 1)]\n",
    "        \n",
    "    def reset(self, init_term=None):\n",
    "        if init_term == None:\n",
    "            t = self.conf_gen()\n",
    "        else:\n",
    "            t = init_term\n",
    "        self.term = t\n",
    "        self.aidx = self.get_aidx(t)\n",
    "        #self.nbrs = [t for t,_,_,_ in t.search(1, m.parseTerm('X:Conf'), depth = 1)]\n",
    "        self.nbrs = [(t,self.get_aidx(t)) for t,_,_,_ in t.search(1, m.parseTerm('X:Conf'), depth = 1)]\n",
    "        \n",
    "        self.available_actions = [action for (_,action) in self.nbrs]\n",
    "        self.mask = np.ones(2 ** self.n_pred, dtype=int)\n",
    "        self.mask[self.available_actions] = 0\n",
    "        return {\n",
    "            'term' : self.term,\n",
    "            'aidx' : self.aidx,\n",
    "            'nbrs' : self.nbrs,\n",
    "            'mask' : self.mask\n",
    "        }\n",
    "        \n",
    "    def step(self, action):\n",
    "        pairs = [(term, aidx) for (term,aidx) in self.nbrs if aidx == action]\n",
    "        if pairs == []:\n",
    "            raise Exception(\"invalid action\")\n",
    "        #nbrs = [t for t in self.nbrs if self.get_aidx(t) == action]\n",
    "        #if nbrs == []:\n",
    "        #    raise Exception(\"invalid action\")\n",
    "        state = self.reset(random.choice(pairs)[0])\n",
    "        done = True if self.available_actions == [] else False\n",
    "        reward = 1 if done else 0\n",
    "        return state, reward, done\n",
    "    \n",
    "    def get_aidx(self, t):\n",
    "        aidx = m.parseTerm('aidx(' + t.prettyPrint(0) + ')')\n",
    "        aidx.reduce()\n",
    "        return aidx.toInt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cda681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_greedy_policy(Qtable, state):\n",
    "    # Exploitation: take the action with the highest state, action value\n",
    "    aidx = state[\"aidx\"]\n",
    "    mask = state[\"mask\"]\n",
    "    #mask = np.where(True, mask^1, mask) # flip 0 & 1\n",
    "    if 0 in mask:\n",
    "        masked_Q = ma.masked_array(Qtable[aidx][:], mask=mask)\n",
    "        action = np.argmax(masked_Q)\n",
    "    else:\n",
    "        action = -1 # deadlock\n",
    "    return action\n",
    "\n",
    "def abs_epsilon_greedy_policy(Qtable, state, epsilon):\n",
    "    # Randomly generate a number between 0 and 1\n",
    "    random_num = random.uniform(0, 1)\n",
    "    # if random_num > greater than epsilon --> exploitation\n",
    "    if random_num > epsilon:\n",
    "        # Take the action with the highest value given a state\n",
    "        # np.argmax can be useful here\n",
    "        action = abs_greedy_policy(Qtable, state)\n",
    "    # else --> exploration\n",
    "    else:\n",
    "        nbrs = state[\"nbrs\"]\n",
    "        if nbrs != []:\n",
    "            action = random.choice(nbrs)[1]\n",
    "        else:\n",
    "            action = -1\n",
    "    return action\n",
    "\n",
    "def abs_train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable):\n",
    "    for episode in tqdm(range(n_training_episodes)):\n",
    "        # Reduce epsilon (because we need less and less exploration)\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay_rate * episode)\n",
    "        # Reset the environment\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "\n",
    "        # repeat\n",
    "        for step in range(max_steps):\n",
    "            # Choose the action At using epsilon greedy policy\n",
    "            s = state[\"aidx\"]\n",
    "            a = abs_epsilon_greedy_policy(Qtable, state, epsilon)\n",
    "            \n",
    "            # assert action not -1\n",
    "            if a == -1:\n",
    "                break\n",
    "\n",
    "            # Take action At and observe Rt+1 and St+1\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, done = env.step(a)\n",
    "\n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "\n",
    "            Qtable[s][a] = Qtable[s][a] + learning_rate * (\n",
    "                reward + gamma * np.max(Qtable[a]) - Qtable[s][a]\n",
    "            )\n",
    "\n",
    "            # If terminated or truncated finish the episode\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            # Our next state is the new state\n",
    "            state = new_state\n",
    "    print('training done!')\n",
    "    return Qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f76ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "n_training_episodes = 1000  # Total training episodes\n",
    "learning_rate = 0.7  # Learning rate\n",
    "\n",
    "# Evaluation parameters\n",
    "n_eval_episodes = 100  # Total number of test episodes\n",
    "\n",
    "# Environment parameters\n",
    "#env_id = \"FrozenLake-v1\"  # Name of the environment\n",
    "max_steps = 300  # Max steps per episode\n",
    "gamma = 0.95  # Discounting rate\n",
    "eval_seed = []  # The evaluation seed of the environment\n",
    "\n",
    "# Exploration parameters\n",
    "max_epsilon = 1.0  # Exploration probability at start\n",
    "min_epsilon = 0.05  # Minimum exploration probability\n",
    "decay_rate = 0.0005  # Exponential decay rate for exploration prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02eb5d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68a43f4b2594ed2938ade8d2e326913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training done!\n"
     ]
    }
   ],
   "source": [
    "env = MaudeEnv(dp_generator)\n",
    "Qtable = np.zeros(shape=(16,16))\n",
    "Qtable = abs_train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c172b079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absQtable density: 43 / 256\n",
      "(16, 16)\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.665      0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.857375   0.         0.         0.         0.\n",
      "  0.85731875 0.81450625 0.         0.        ]\n",
      " [0.         0.         1.         0.         0.         0.81450625\n",
      "  0.95       0.857375   0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.81450625\n",
      "  0.         0.857375   0.         0.         0.         0.\n",
      "  0.         0.         0.9025     0.857375  ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.85043026 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.74633208 0.77377637 0.         0.\n",
      "  0.         0.81450625 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.95       0.         0.         0.77378094 0.         0.857375\n",
      "  0.         0.         0.9025     0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.857375   0.         0.77378094 0.9025     0.857375\n",
      "  0.         0.         0.         0.857375  ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.9025     0.\n",
      "  0.857375   0.         0.9025     0.        ]\n",
      " [0.         0.         0.         0.         0.         0.81450625\n",
      "  0.         0.         0.         0.         0.         0.857375\n",
      "  0.857375   0.81450625 0.         0.857375  ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.95       0.         0.         0.         0.9025     0.\n",
      "  0.         0.81450625 0.9025     0.857375  ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.857375   0.         0.         0.         0.857375\n",
      "  0.         0.81450625 0.9025     0.857375  ]]\n"
     ]
    }
   ],
   "source": [
    "print('absQtable density:', np.count_nonzero(Qtable), '/', Qtable.size)\n",
    "print(Qtable.shape)\n",
    "print(Qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b8c3ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e-greedy Simulator\n",
    "def abs_simulate(Qtable, max_steps=1000, epsilon=0.01):\n",
    "    state = env.reset()\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        # Choose the action At using epsilon greedy policy\n",
    "        action = abs_epsilon_greedy_policy(Qtable, state, epsilon)\n",
    "        if action == -1:\n",
    "            break\n",
    "\n",
    "        # Take action At and observe Rt+1 and St+1\n",
    "        # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "        new_state, reward, done = env.step(action)\n",
    "\n",
    "        # If terminated or truncated finish the episode\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        # Our next state is the new state\n",
    "        state = new_state\n",
    "        \n",
    "    return step + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bec9c8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16bd17a627df459facef430a1026bddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained:\n",
      "[17, 13, 1, 2, 23, 16, 34, 11, 38, 33, 8, 43, 12, 37, 10, 22, 3, 22, 64, 16, 10, 7, 67, 26, 15, 12, 4, 16, 13, 30, 39, 6, 6, 10, 9, 11, 17, 22, 13, 15, 47, 24, 24, 13, 17, 62, 54, 20, 10, 12, 6, 28, 8, 19, 38, 67, 8, 9, 24, 15, 28, 5, 21, 13, 17, 5, 4, 3, 35, 14, 8, 9, 48, 6, 22, 1, 13, 17, 5, 6, 7, 13, 27, 12, 4, 7, 7, 6, 30, 23, 4, 84, 20, 1, 5, 7, 13, 58, 20, 7]\n",
      "avg:\n",
      "19.13\n",
      "=====\n",
      "random:\n",
      "[30, 62, 133, 115, 26, 153, 19, 3, 86, 125, 65, 102, 213, 88, 122, 25, 37, 17, 62, 197, 20, 89, 77, 5, 228, 127, 22, 12, 91, 1, 198, 186, 105, 104, 100, 137, 81, 60, 64, 8, 138, 179, 37, 57, 115, 45, 116, 12, 46, 11, 105, 17, 12, 113, 130, 23, 153, 63, 87, 109, 56, 59, 139, 21, 77, 78, 122, 9, 80, 58, 120, 279, 31, 10, 157, 75, 31, 146, 160, 23, 95, 175, 96, 139, 2, 175, 144, 20, 108, 38, 37, 5, 130, 21, 63, 3, 12, 84, 52, 48]\n",
      "avg:\n",
      "81.41\n"
     ]
    }
   ],
   "source": [
    "max_steps = 1000\n",
    "res_trained = []\n",
    "res_random = []\n",
    "for _ in tqdm(range(100)):\n",
    "    num_steps_trained = abs_simulate(Qtable, max_steps=max_steps, epsilon=0)\n",
    "    num_steps_random = abs_simulate(Qtable, max_steps=max_steps, epsilon=1)\n",
    "    res_trained.append(num_steps_trained)\n",
    "    res_random.append(num_steps_random)\n",
    "print('trained:')\n",
    "print(res_trained)\n",
    "print('avg:')\n",
    "print(np.average(res_trained))\n",
    "print('=====')\n",
    "print('random:')\n",
    "print(res_random)\n",
    "print('avg:')\n",
    "print(np.average(res_random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "90e50ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = MaudeEnv(dp_generator)\n",
    "env.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8a5f1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "Qtable = np.zeros(shape=(16,16))\n",
    "print(Qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "25ca2539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term: c(1) || c(3) || c(4) || c(5) || p(0, single) || p(1, think) || p(2, single) || p(3, think) || p(4, think) || p(5, hungry)\n",
      "action (next aidx): 14\n",
      "action: 14, state: {'term': c(1) || c(3) || c(4) || c(5) || p(0, single) || p(1, hungry) || p(2, single) || p(3, think) || p(4, think) || p(5, hungry), 'aidx': 14, 'nbrs': [(c(3) || c(4) || c(5) || p(0, single) || p(1, single) || p(2, single) || p(3, think) || p(4, think) || p(5, hungry), 14), (c(1) || c(3) || c(4) || p(0, single) || p(1, hungry) || p(2, single) || p(3, think) || p(4, think) || p(5, single), 14), (c(3) || c(4) || c(5) || p(0, eat) || p(1, hungry) || p(2, single) || p(3, think) || p(4, think) || p(5, hungry), 15), (c(1) || c(3) || c(4) || c(5) || p(0, single) || p(1, hungry) || p(2, single) || p(3, hungry) || p(4, think) || p(5, hungry), 14), (c(1) || c(3) || c(4) || c(5) || p(0, single) || p(1, hungry) || p(2, single) || p(3, think) || p(4, hungry) || p(5, hungry), 14)], 'mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0])}, reward: 0, done: False\n",
      "===\n",
      "term: c(1) || c(3) || c(4) || c(5) || p(0, single) || p(1, hungry) || p(2, single) || p(3, think) || p(4, think) || p(5, hungry)\n",
      "action (next aidx): 14\n",
      "action: 14, state: {'term': c(1) || c(3) || c(4) || p(0, single) || p(1, hungry) || p(2, single) || p(3, think) || p(4, think) || p(5, single), 'aidx': 14, 'nbrs': [(c(3) || c(4) || p(0, single) || p(1, single) || p(2, single) || p(3, think) || p(4, think) || p(5, single), 10), (c(3) || c(4) || p(0, eat) || p(1, hungry) || p(2, single) || p(3, think) || p(4, think) || p(5, single), 15), (c(1) || c(3) || c(4) || p(0, single) || p(1, hungry) || p(2, single) || p(3, hungry) || p(4, think) || p(5, single), 14), (c(1) || c(3) || c(4) || p(0, single) || p(1, hungry) || p(2, single) || p(3, think) || p(4, hungry) || p(5, single), 14)], 'mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0])}, reward: 0, done: False\n",
      "===\n",
      "term: c(1) || c(3) || c(4) || p(0, single) || p(1, hungry) || p(2, single) || p(3, think) || p(4, think) || p(5, single)\n",
      "action (next aidx): 15\n",
      "action: 15, state: {'term': c(3) || c(4) || p(0, eat) || p(1, hungry) || p(2, single) || p(3, think) || p(4, think) || p(5, single), 'aidx': 15, 'nbrs': [(c(0) || c(1) || c(3) || c(4) || p(0, think) || p(1, hungry) || p(2, single) || p(3, think) || p(4, think) || p(5, single), 14), (c(3) || c(4) || p(0, eat) || p(1, hungry) || p(2, single) || p(3, hungry) || p(4, think) || p(5, single), 15), (c(3) || c(4) || p(0, eat) || p(1, hungry) || p(2, single) || p(3, think) || p(4, hungry) || p(5, single), 15)], 'mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0])}, reward: 0, done: False\n",
      "===\n",
      "term: c(3) || c(4) || p(0, eat) || p(1, hungry) || p(2, single) || p(3, think) || p(4, think) || p(5, single)\n",
      "action (next aidx): 14\n",
      "action: 14, state: {'term': c(0) || c(1) || c(3) || c(4) || p(0, think) || p(1, hungry) || p(2, single) || p(3, think) || p(4, think) || p(5, single), 'aidx': 14, 'nbrs': [(c(0) || c(3) || c(4) || p(0, think) || p(1, single) || p(2, single) || p(3, think) || p(4, think) || p(5, single), 10), (c(1) || c(3) || c(4) || p(0, think) || p(1, hungry) || p(2, eat) || p(3, think) || p(4, think) || p(5, single), 15), (c(0) || c(1) || c(3) || c(4) || p(0, hungry) || p(1, hungry) || p(2, single) || p(3, think) || p(4, think) || p(5, single), 14), (c(0) || c(1) || c(3) || c(4) || p(0, think) || p(1, hungry) || p(2, single) || p(3, hungry) || p(4, think) || p(5, single), 14), (c(0) || c(1) || c(3) || c(4) || p(0, think) || p(1, hungry) || p(2, single) || p(3, think) || p(4, hungry) || p(5, single), 14)], 'mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0])}, reward: 0, done: False\n",
      "===\n",
      "term: c(0) || c(1) || c(3) || c(4) || p(0, think) || p(1, hungry) || p(2, single) || p(3, think) || p(4, think) || p(5, single)\n",
      "action (next aidx): 10\n",
      "action: 10, state: {'term': c(0) || c(3) || c(4) || p(0, think) || p(1, single) || p(2, single) || p(3, think) || p(4, think) || p(5, single), 'aidx': 10, 'nbrs': [(c(3) || c(4) || p(0, think) || p(1, single) || p(2, eat) || p(3, think) || p(4, think) || p(5, single), 11), (c(0) || c(3) || c(4) || p(0, hungry) || p(1, single) || p(2, single) || p(3, think) || p(4, think) || p(5, single), 14), (c(0) || c(3) || c(4) || p(0, think) || p(1, single) || p(2, single) || p(3, hungry) || p(4, think) || p(5, single), 14), (c(0) || c(3) || c(4) || p(0, think) || p(1, single) || p(2, single) || p(3, think) || p(4, hungry) || p(5, single), 14)], 'mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1])}, reward: 0, done: False\n",
      "===\n",
      "term: c(0) || c(3) || c(4) || p(0, think) || p(1, single) || p(2, single) || p(3, think) || p(4, think) || p(5, single)\n",
      "action (next aidx): 14\n",
      "action: 14, state: {'term': c(0) || c(3) || c(4) || p(0, think) || p(1, single) || p(2, single) || p(3, think) || p(4, hungry) || p(5, single), 'aidx': 14, 'nbrs': [(c(0) || c(3) || p(0, think) || p(1, single) || p(2, single) || p(3, think) || p(4, single) || p(5, single), 10), (c(3) || c(4) || p(0, think) || p(1, single) || p(2, eat) || p(3, think) || p(4, hungry) || p(5, single), 15), (c(0) || c(3) || c(4) || p(0, hungry) || p(1, single) || p(2, single) || p(3, think) || p(4, hungry) || p(5, single), 14), (c(0) || c(3) || c(4) || p(0, think) || p(1, single) || p(2, single) || p(3, hungry) || p(4, hungry) || p(5, single), 14)], 'mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0])}, reward: 0, done: False\n",
      "===\n",
      "term: c(0) || c(3) || c(4) || p(0, think) || p(1, single) || p(2, single) || p(3, think) || p(4, hungry) || p(5, single)\n",
      "action (next aidx): 14\n",
      "action: 14, state: {'term': c(0) || c(3) || c(4) || p(0, think) || p(1, single) || p(2, single) || p(3, hungry) || p(4, hungry) || p(5, single), 'aidx': 14, 'nbrs': [(c(0) || c(4) || p(0, think) || p(1, single) || p(2, single) || p(3, single) || p(4, hungry) || p(5, single), 14), (c(0) || c(3) || p(0, think) || p(1, single) || p(2, single) || p(3, hungry) || p(4, single) || p(5, single), 14), (c(3) || c(4) || p(0, think) || p(1, single) || p(2, eat) || p(3, hungry) || p(4, hungry) || p(5, single), 15), (c(0) || c(3) || c(4) || p(0, hungry) || p(1, single) || p(2, single) || p(3, hungry) || p(4, hungry) || p(5, single), 6)], 'mask': array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0])}, reward: 0, done: False\n",
      "===\n",
      "term: c(0) || c(3) || c(4) || p(0, think) || p(1, single) || p(2, single) || p(3, hungry) || p(4, hungry) || p(5, single)\n",
      "action (next aidx): 14\n",
      "action: 14, state: {'term': c(0) || c(4) || p(0, think) || p(1, single) || p(2, single) || p(3, single) || p(4, hungry) || p(5, single), 'aidx': 14, 'nbrs': [(c(0) || p(0, think) || p(1, single) || p(2, single) || p(3, single) || p(4, single) || p(5, single), 10), (c(4) || p(0, think) || p(1, single) || p(2, eat) || p(3, single) || p(4, hungry) || p(5, single), 15), (c(0) || c(4) || p(0, hungry) || p(1, single) || p(2, single) || p(3, single) || p(4, hungry) || p(5, single), 6)], 'mask': array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0])}, reward: 0, done: False\n",
      "===\n",
      "term: c(0) || c(4) || p(0, think) || p(1, single) || p(2, single) || p(3, single) || p(4, hungry) || p(5, single)\n",
      "action (next aidx): 6\n",
      "action: 6, state: {'term': c(0) || c(4) || p(0, hungry) || p(1, single) || p(2, single) || p(3, single) || p(4, hungry) || p(5, single), 'aidx': 6, 'nbrs': [(c(4) || p(0, single) || p(1, single) || p(2, single) || p(3, single) || p(4, hungry) || p(5, single), 6), (c(0) || p(0, hungry) || p(1, single) || p(2, single) || p(3, single) || p(4, single) || p(5, single), 6), (c(4) || p(0, hungry) || p(1, single) || p(2, eat) || p(3, single) || p(4, hungry) || p(5, single), 7)], 'mask': array([1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])}, reward: 0, done: False\n",
      "===\n",
      "term: c(0) || c(4) || p(0, hungry) || p(1, single) || p(2, single) || p(3, single) || p(4, hungry) || p(5, single)\n",
      "action (next aidx): 6\n",
      "action: 6, state: {'term': c(0) || p(0, hungry) || p(1, single) || p(2, single) || p(3, single) || p(4, single) || p(5, single), 'aidx': 6, 'nbrs': [(p(0, single) || p(1, single) || p(2, single) || p(3, single) || p(4, single) || p(5, single), 2), (p(0, hungry) || p(1, single) || p(2, eat) || p(3, single) || p(4, single) || p(5, single), 7)], 'mask': array([1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1])}, reward: 0, done: False\n",
      "===\n",
      "term: c(0) || p(0, hungry) || p(1, single) || p(2, single) || p(3, single) || p(4, single) || p(5, single)\n",
      "action (next aidx): 2\n",
      "action: 2, state: {'term': p(0, single) || p(1, single) || p(2, single) || p(3, single) || p(4, single) || p(5, single), 'aidx': 2, 'nbrs': [], 'mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}, reward: 1, done: True\n",
      "===\n",
      "last term: p(0, single) || p(1, single) || p(2, single) || p(3, single) || p(4, single) || p(5, single)\n"
     ]
    }
   ],
   "source": [
    "#t = m.parseTerm(\"p(0,think) || c(0) || p(s(0),think) || c(s(0)) || p(s(s(0)),think) || c(s(s(0)))\")\n",
    "env = MaudeEnv(dp_generator)\n",
    "\n",
    "while env.available_actions != []:\n",
    "    print('term:', env.term)\n",
    "    #print('aidx:', env.aidx)\n",
    "    action = random.choice(env.available_actions)\n",
    "    print('action (next aidx):', action)\n",
    "    state, reward, done = env.step(action)\n",
    "    print(f'action: {action}, state: {state}, reward: {reward}, done: {done}')\n",
    "    print('===')\n",
    "print('last term:', env.term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "635332df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(0, single) || p(1, hungry) || p(2, eat) || p(3, hungry) || p(4, eat)\n",
      "15\n",
      "{'term': c(2) || c(3) || p(0, single) || p(1, hungry) || p(2, think) || p(3, hungry) || p(4, eat), 'aidx': 15, 'nbrs': [(c(3) || p(0, single) || p(1, single) || p(2, think) || p(3, hungry) || p(4, eat), 15), (c(2) || p(0, single) || p(1, hungry) || p(2, think) || p(3, single) || p(4, eat), 15), (c(2) || c(3) || p(0, single) || p(1, hungry) || p(2, hungry) || p(3, hungry) || p(4, eat), 7), (c(0) || c(2) || c(3) || c(4) || p(0, single) || p(1, hungry) || p(2, think) || p(3, hungry) || p(4, think), 14)], 'mask': array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0])} False\n"
     ]
    }
   ],
   "source": [
    "tterm = m.parseTerm('p(0, single) || p(1, hungry) || p(2, eat) || p(3, hungry) || p(4, eat)')\n",
    "print(tterm)\n",
    "tenv = MaudeEnv(dp_generator, tterm)\n",
    "state = tenv.reset(tterm)\n",
    "#print(state)\n",
    "a = abs_greedy_policy(Qtable, state)\n",
    "print(a)\n",
    "state, reward, done = tenv.step(a)\n",
    "print(state, done)\n",
    "#print(abs_epsilon_greedy_policy(Qtable, state, 0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
